{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nrVJJ9YHoiPh",
        "outputId": "b80799b5-067a-431e-e71c-275a3a72705b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.44.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.2 (from pennylane)\n",
            "  Downloading autoray-0.8.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.6)\n",
            "Collecting pennylane-lightning>=0.44 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.44->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.31.22.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.46.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.44.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.2-py3-none-any.whl (935 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.31.22.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.2 diastatic-malt-2.15.2 pennylane-0.44.0 pennylane-lightning-0.44.0 rustworkx-0.17.1 scipy-openblas32-0.3.31.22.1\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: pennylane-lightning[gpu] in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray==0.8.2 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning[gpu]) (0.3.31.22.1)\n",
            "Collecting pennylane-lightning-gpu (from pennylane-lightning[gpu])\n",
            "  Downloading pennylane_lightning_gpu-0.44.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Collecting custatevec-cu12 (from pennylane-lightning-gpu->pennylane-lightning[gpu])\n",
            "  Downloading custatevec_cu12-1.12.0-py3-none-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.6.77)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.46.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane_lightning_gpu-0.44.0-cp312-cp312-manylinux_2_28_x86_64.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.3/913.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading custatevec_cu12-1.12.0-py3-none-manylinux2014_x86_64.whl (73.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: custatevec-cu12, pennylane-lightning-gpu\n",
            "Successfully installed custatevec-cu12-1.12.0 pennylane-lightning-gpu-0.44.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane\n",
        "!pip install pennylane pennylane-lightning[gpu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KROFpzJsoxfN"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2-JpS4QpoxBj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pennylane as qml\n",
        "from pennylane.templates import QFT\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import fetch_openml, load_digits\n",
        "from sklearn.preprocessing import MinMaxScaler, normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from pennylane import numpy as pnp\n",
        "from skimage.transform import resize\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPeJfiDJo-qn"
      },
      "source": [
        "### Step 1:  Dataset Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we load the MNIST dataset from openML.\n",
        "- X is the pixel data\n",
        "- y is the labels\n",
        "- converting everything to `uint8` here to ensure all values are integers in [0, 255]"
      ],
      "metadata": {
        "id": "5JJh_V_1hfrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "amm-B8_Xdzyf"
      },
      "outputs": [],
      "source": [
        "# loading mnist from openML\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist['data'].astype(np.uint8) # better to convert for binerization\n",
        "y = mnist['target'].astype(np.uint8)\n",
        "y = y.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeMOrBB2ognh"
      },
      "source": [
        "Next, we focus on 2 classes, i.e. binary classification.\n",
        "Here, I've been experimenting with different classes, and I stopped on 4 vs 9, cause they have more subtle difference in pixels, they are similar looking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNShS1qTpNI7",
        "outputId": "21695e81-722f-4230-dc2e-21235c7e6e25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13782, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# focus on binary classification\n",
        "mask = (y == 4) | (y == 9)\n",
        "X, y = X[mask], y[mask]\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I take only the first `n_samples`.\n",
        "- I convert X to a NumPy array, and shuffling the data randomly"
      ],
      "metadata": {
        "id": "6qdDAqkBizaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "GdbQMsOdpoWz"
      },
      "outputs": [],
      "source": [
        "n_samples = 100 # restricting to 6000 samples for now\n",
        "\n",
        "X = X.values if hasattr(X, \"values\") else X # safer conversion\n",
        "perm = np.random.permutation(len(X))\n",
        "X, y = X[perm], y[perm]\n",
        "\n",
        "X = X[:n_samples]\n",
        "y = y[:n_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFV8_UnGptzJ"
      },
      "source": [
        "Now, I normalise pixel intensities.\n",
        "- [0, 255] -> [0, 1]\n",
        "- reshaping images back to 2D for resizing, i.e to 28x28 array with float values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A69wNTvdppCb",
        "outputId": "30150f97-8d64-4f11-bd23-2bb9ea6757d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 28, 28)\n",
            "Pixel range: 0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "X = X / 255.0\n",
        "X = X.reshape(-1, 28, 28)\n",
        "\n",
        "print(X.shape)\n",
        "print(\"Pixel range:\", X.min(), X.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6fKM38QpyO8"
      },
      "source": [
        "And now I reduce images to 8x8 + flattening to (, 64)\n",
        "- resize -> flatten -> normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXfPx1nwpq31",
        "outputId": "ecfd44ac-3450-4854-ff48-5a8aae6e4ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# convert each 28x28 binarised image to 8x8, then flatten to length 64\n",
        "def to_8x8_vector(img_row):\n",
        "    img_8x8 = resize(\n",
        "        img_row,\n",
        "        (8, 8),\n",
        "        anti_aliasing=False,\n",
        "        preserve_range=True,\n",
        "        order=1 # controlling interpolation\n",
        "    )\n",
        "    img_8x8 = img_8x8.flatten()\n",
        "    s = np.sum(img_8x8)\n",
        "\n",
        "    if s > 0:\n",
        "        img_8x8 = np.sqrt(img_8x8 / s)\n",
        "    else:\n",
        "        img_8x8 = np.zeros_like(img_8x8)\n",
        "        img_8x8[0] = 1.0\n",
        "      # should be shape (64,)\n",
        "    return img_8x8\n",
        "\n",
        "# apply transformation to all images\n",
        "X_8x8 = np.array([to_8x8_vector(x) for x in X], dtype=float)\n",
        "X_8x8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycrMsoOtp2BY",
        "outputId": "e900a630-8997-4649-9d45-a99de273f3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any NaNs? False\n",
            "Norm check: 0.9999999999999999 1.0\n"
          ]
        }
      ],
      "source": [
        "# sanity check, make sure no NaNs exist and all vectors are normalised, i.e. norm is around 1\n",
        "print(\"Any NaNs?\", np.isnan(X_8x8).any())\n",
        "print(\"Norm check:\", np.min(np.linalg.norm(X_8x8, axis=1)), np.max(np.linalg.norm(X_8x8, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUuSiBQfp_Sf"
      },
      "source": [
        "I'm gonna do the splitting here, and carry both representations consistently.\n",
        "- qek inputs: (64,) flattened and normalized vectors, for quantum kernel embedding\n",
        "- qjpeg: 28x28 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbFUj8-Zp9fc",
        "outputId": "623c3a91-9931-4d1a-df52-d6bf2fcae100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QEK train/test: (80, 64) (20, 64)\n",
            "IMG train/test: (80, 28, 28) (20, 28, 28)\n",
            "Labels train/test: (80,) (20,)\n"
          ]
        }
      ],
      "source": [
        "idx = np.arange(n_samples)\n",
        "\n",
        "idx_train, idx_test, y_train, y_test = train_test_split(\n",
        "    idx, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# QEK inputs (8x8 -> 64 -> normed)\n",
        "X_train_qek = X_8x8[idx_train]\n",
        "X_test_qek  = X_8x8[idx_test]\n",
        "\n",
        "# QJPEG inputs (28x28 binary images)\n",
        "X_train_img = X[idx_train]\n",
        "X_test_img  = X[idx_test]\n",
        "\n",
        "print(\"QEK train/test:\", X_train_qek.shape, X_test_qek.shape)\n",
        "print(\"IMG train/test:\", X_train_img.shape, X_test_img.shape)\n",
        "print(\"Labels train/test:\", y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQUmF-0YqOjS"
      },
      "source": [
        "Data preparation is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxklKVp_qRRT"
      },
      "source": [
        "### Step 2: Quantum Embedding & Kernel Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define number of qubits and device."
      ],
      "metadata": {
        "id": "DiuzYJktY-lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"lightning.gpu\"\n",
        "n_qubits = 6"
      ],
      "metadata": {
        "id": "g1l-xD10kYsG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NDnTjviKqYmk"
      },
      "outputs": [],
      "source": [
        "dev = qml.device(device, wires=n_qubits, shots=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54-8ETQgqrnD"
      },
      "source": [
        "Defining the parametrised quantum circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "vcR07EVnqp_8"
      },
      "outputs": [],
      "source": [
        "def qek_layer_amplitude(x, theta_l):\n",
        "    # Data re-uploading via phase gates (breaks kernel symmetry)\n",
        "    for q in range(n_qubits):\n",
        "        qml.RZ(np.pi * x[q], wires=q)\n",
        "\n",
        "    # Trainable block\n",
        "    for q in range(n_qubits):\n",
        "        qml.RX(theta_l[q, 0], wires=q)\n",
        "        qml.RZ(theta_l[q, 1], wires=q)\n",
        "\n",
        "    # Entanglement (non-commuting)\n",
        "    for q in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[q, q + 1])\n",
        "\n",
        "def qek_embedding_amplitude(x, theta):\n",
        "    qml.AmplitudeEmbedding(\n",
        "        x,\n",
        "        wires=range(n_qubits),\n",
        "        normalize=True\n",
        "    )\n",
        "\n",
        "    for l in range(theta.shape[0]):\n",
        "        qek_layer_amplitude(x, theta[l])\n",
        "\n",
        "# quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def qek_kernel_circuit(x1, x2, theta):\n",
        "    qek_embedding_amplitude(x1, theta)\n",
        "    qml.adjoint(qek_embedding_amplitude)(x2, theta)\n",
        "    return qml.probs(wires=range(n_qubits))\n",
        "\n",
        "def qek_kernel(x1, x2, theta):\n",
        "    # Fidelity = probability of |0...0>\n",
        "    return qek_kernel_circuit(x1, x2, theta)[0]\n",
        "\n",
        "# compute kernel matrix\n",
        "def square_kernel_matrix(X, theta):\n",
        "    n = len(X)\n",
        "    K = pnp.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(i, n):\n",
        "            val = qek_kernel(X[i], X[j], theta)\n",
        "            K[i, j] = val\n",
        "            K[j, i] = val\n",
        "    return K\n",
        "\n",
        "\n",
        "def rectangular_kernel_matrix(X1, X2, theta):\n",
        "    K = np.zeros((len(X1), len(X2)))\n",
        "    for i in range(len(X1)):\n",
        "        for j in range(len(X2)):\n",
        "            K[i, j] = qek_kernel(X1[i], X2[j], theta)\n",
        "    return K\n",
        "\n",
        "def centered_kernel_alignment(K, y):\n",
        "    y = y.astype(float)\n",
        "    y = 2 * y - 1          # {0,1} → {-1,+1}\n",
        "    yyT = np.outer(y, y)\n",
        "\n",
        "    Kc = K - K.mean(axis=0) - K.mean(axis=1)[:, None] + K.mean()\n",
        "    return -np.sum(Kc * yyT) / (np.linalg.norm(Kc) + 1e-8)\n",
        "\n",
        "def kernel_alignment_loss(theta, X, y, batch_size=10):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    Xb = X[idx]\n",
        "    yb = y[idx]\n",
        "\n",
        "    K = square_kernel_matrix(Xb, theta)\n",
        "    return centered_kernel_alignment(K, yb)\n",
        "\n",
        "def feature_map(x, theta):\n",
        "    # Amplitude encoding (always normalized)\n",
        "    qml.AmplitudeEmbedding(x, wires=wires, normalize=False)\n",
        "\n",
        "    # Variational re-uploading layers\n",
        "    for l in range(theta.shape[0]):\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(theta[l, i, 0], wires=i)\n",
        "            qml.RY(theta[l, i, 1], wires=i)\n",
        "            qml.RZ(theta[l, i, 2], wires=i)\n",
        "\n",
        "        # Entangling layer (ring or chain)\n",
        "        for i in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i + 1])\n",
        "        qml.CNOT(wires=[n_qubits - 1, 0])\n",
        "\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def kernel_qnode(x1, x2, theta):\n",
        "    feature_map(x1, theta)\n",
        "    qml.adjoint(feature_map)(x2, theta)\n",
        "    return qml.expval(qml.Projector([0]*n_qubits, wires=wires))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RtTvYKYRXqLO"
      },
      "outputs": [],
      "source": [
        "n_qubits = 6\n",
        "n_layers = 4          # number of trainable layers\n",
        "batch_size = 8       # bigger batch for stability\n",
        "n_steps = 50          # training steps\n",
        "stepsize = 0.0005       # smaller learning rate\n",
        "eps_trace = 1e-8      # small epsilon to prevent division by zero\n",
        "wires = range(n_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "07tRKk_SfEFc"
      },
      "outputs": [],
      "source": [
        "def kernel_matrix(X1, X2, theta):\n",
        "    return qml.math.stack([\n",
        "        qml.math.stack([\n",
        "            kernel_qnode(x1, x2, theta)\n",
        "            for x2 in X2\n",
        "        ])\n",
        "        for x1 in X1\n",
        "    ])\n",
        "\n",
        "def kernel_alignment_loss_batch(theta, X, y, batch_size):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    Xb = X[idx]\n",
        "    yb = y[idx]\n",
        "\n",
        "    # Kernel\n",
        "    K = kernel_matrix(Xb, Xb, theta)\n",
        "    K = K / pnp.trace(K)\n",
        "    K /= pnp.linalg.norm(K)\n",
        "\n",
        "    # Labels: {0,1} → {−1,+1}\n",
        "    y_pm = 2 * yb - 1\n",
        "    yy = qml.math.outer(y_pm, y_pm)\n",
        "\n",
        "    # Center kernel\n",
        "    Kc = center_kernel(K)\n",
        "    Kc = Kc / pnp.trace(Kc)\n",
        "\n",
        "    # Flatten\n",
        "    Kf = qml.math.reshape(Kc, (-1,))\n",
        "    yyf = qml.math.reshape(yy, (-1,))\n",
        "\n",
        "    # Kernel Target Alignment\n",
        "    numerator = qml.math.dot(Kf, yyf)\n",
        "    denominator = qml.math.sqrt(\n",
        "        qml.math.dot(Kf, Kf) * qml.math.dot(yyf, yyf)\n",
        "    )\n",
        "\n",
        "    return -numerator / denominator\n",
        "\n",
        "def kernel_alignment_loss_minibatch(theta, X, y, batch_pairs=20):\n",
        "    idx = np.random.choice(len(X), size=batch_pairs, replace=True)\n",
        "\n",
        "    K_vals = []\n",
        "    y_vals = []\n",
        "\n",
        "    for i in idx:\n",
        "        for j in idx:\n",
        "            K_vals.append(qek_kernel(X[i], X[j], theta))\n",
        "            y_vals.append(y[i] * y[j])\n",
        "\n",
        "    K_vec = pnp.array(K_vals)\n",
        "    y_vec = pnp.array(y_vals)\n",
        "\n",
        "    return - pnp.dot(K_vec, y_vec) / (\n",
        "        pnp.linalg.norm(K_vec) * pnp.linalg.norm(y_vec)\n",
        "    )\n",
        "\n",
        "def normalized_kernel_alignment(K, y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    Ky = y @ y.T\n",
        "\n",
        "    K_norm = K / qml.numpy.linalg.norm(K)\n",
        "    Ky_norm = Ky / qml.numpy.linalg.norm(Ky)\n",
        "\n",
        "    return 1 - qml.numpy.sum(K_norm * Ky_norm)\n",
        "\n",
        "def kernel_alignment_loss(theta, X, y):\n",
        "    K = square_kernel_matrix(X, theta)\n",
        "    return normalized_kernel_alignment(K, y)\n",
        "\n",
        "def center_kernel(K):\n",
        "    n = K.shape[0]\n",
        "    H = qml.numpy.eye(n) - qml.numpy.ones((n, n)) / n\n",
        "    return H @ K @ H\n",
        "\n",
        "def smooth_step(theta, k=5):\n",
        "    grads = []\n",
        "    for _ in range(k):\n",
        "        _, g = opt.step_and_cost(loss_fn, theta)\n",
        "        grads.append(g)\n",
        "    return np.mean(grads, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers_list = [1, 2, 4, 6, 8, 10, 12]\n",
        "\n",
        "ema = None\n",
        "alpha = 0.9\n",
        "\n",
        "for L in layers_list:\n",
        "    print(f\"\\nTraining expressive circuit with {L} layers\")\n",
        "    # Initialize theta with the correct shape (L, n_qubits, 3) for the feature_map\n",
        "    theta = 0.01 * pnp.random.randn(L, n_qubits, 3)\n",
        "\n",
        "    opt = qml.AdamOptimizer(stepsize=stepsize)\n",
        "\n",
        "    best = np.inf\n",
        "    for step in range(n_steps):\n",
        "        # Use kernel_alignment_loss_batch, which is compatible with Autograd\n",
        "        theta, loss = opt.step_and_cost(\n",
        "            lambda t: kernel_alignment_loss_batch(t, X_train_qek, y_train, batch_size=batch_size),\n",
        "            theta\n",
        "        )\n",
        "        ema = loss if ema is None else alpha * ema + (1 - alpha) * loss\n",
        "\n",
        "        print(f\"Step {step:02d} | loss = {loss:.4f} | ema={ema:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T78NMy5Zyj1",
        "outputId": "0d446e8a-0638-4560-9152-11fdd63dc73d",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training expressive circuit with 1 layers\n",
            "Step 00 | loss = 8.5920 | ema=8.592\n",
            "Step 01 | loss = 14.0837 | ema=9.141\n",
            "Step 02 | loss = 12.6885 | ema=9.496\n",
            "Step 03 | loss = 8.7939 | ema=9.426\n",
            "Step 04 | loss = 16.4761 | ema=10.131\n",
            "Step 05 | loss = 13.2529 | ema=10.443\n",
            "Step 06 | loss = 16.5569 | ema=11.054\n",
            "Step 07 | loss = 10.3312 | ema=10.982\n",
            "Step 08 | loss = 15.0824 | ema=11.392\n",
            "Step 09 | loss = 15.3389 | ema=11.787\n",
            "Step 10 | loss = 18.1585 | ema=12.424\n",
            "Step 11 | loss = 14.8766 | ema=12.669\n",
            "Step 12 | loss = 13.4120 | ema=12.743\n",
            "Step 13 | loss = 10.3785 | ema=12.507\n",
            "Step 14 | loss = 8.9826 | ema=12.155\n",
            "Step 15 | loss = 6.8058 | ema=11.620\n",
            "Step 16 | loss = 21.9497 | ema=12.653\n",
            "Step 17 | loss = 15.0974 | ema=12.897\n",
            "Step 18 | loss = 13.9647 | ema=13.004\n",
            "Step 19 | loss = 19.6129 | ema=13.665\n",
            "Step 20 | loss = 13.2824 | ema=13.627\n",
            "Step 21 | loss = 14.5488 | ema=13.719\n",
            "Step 22 | loss = 10.6750 | ema=13.414\n",
            "Step 23 | loss = 12.2785 | ema=13.301\n",
            "Step 24 | loss = 26.8185 | ema=14.653\n",
            "Step 25 | loss = 11.8141 | ema=14.369\n",
            "Step 26 | loss = 11.7226 | ema=14.104\n",
            "Step 27 | loss = 17.0588 | ema=14.400\n",
            "Step 28 | loss = 13.0249 | ema=14.262\n",
            "Step 29 | loss = 13.9597 | ema=14.232\n",
            "Step 30 | loss = 12.2947 | ema=14.038\n",
            "Step 31 | loss = 18.6626 | ema=14.501\n",
            "Step 32 | loss = 16.0573 | ema=14.656\n",
            "Step 33 | loss = 4.6514 | ema=13.656\n",
            "Step 34 | loss = 5.8704 | ema=12.877\n",
            "Step 35 | loss = 18.6348 | ema=13.453\n",
            "Step 36 | loss = 11.3039 | ema=13.238\n",
            "Step 37 | loss = 16.3621 | ema=13.551\n",
            "Step 38 | loss = 9.6970 | ema=13.165\n",
            "Step 39 | loss = 6.2052 | ema=12.469\n",
            "Step 40 | loss = 7.1467 | ema=11.937\n",
            "Step 41 | loss = 17.0203 | ema=12.445\n",
            "Step 42 | loss = 16.3184 | ema=12.833\n",
            "Step 43 | loss = 18.2735 | ema=13.377\n",
            "Step 44 | loss = 17.8262 | ema=13.822\n",
            "Step 45 | loss = 13.9488 | ema=13.834\n",
            "Step 46 | loss = 12.4643 | ema=13.697\n",
            "Step 47 | loss = 11.6002 | ema=13.488\n",
            "Step 48 | loss = 9.4270 | ema=13.082\n",
            "Step 49 | loss = 16.7685 | ema=13.450\n",
            "\n",
            "Training expressive circuit with 2 layers\n",
            "Step 00 | loss = 21.4090 | ema=14.246\n",
            "Step 01 | loss = 10.0547 | ema=13.827\n",
            "Step 02 | loss = 14.8030 | ema=13.925\n",
            "Step 03 | loss = 16.5779 | ema=14.190\n",
            "Step 04 | loss = 13.7134 | ema=14.142\n",
            "Step 05 | loss = 11.9045 | ema=13.918\n",
            "Step 06 | loss = 15.9366 | ema=14.120\n",
            "Step 07 | loss = 12.0467 | ema=13.913\n",
            "Step 08 | loss = 14.6122 | ema=13.983\n",
            "Step 09 | loss = 11.6483 | ema=13.749\n",
            "Step 10 | loss = 15.1399 | ema=13.888\n",
            "Step 11 | loss = 18.0544 | ema=14.305\n",
            "Step 12 | loss = 15.0228 | ema=14.377\n",
            "Step 13 | loss = 16.0249 | ema=14.542\n",
            "Step 14 | loss = 14.3020 | ema=14.518\n",
            "Step 15 | loss = 17.8213 | ema=14.848\n",
            "Step 16 | loss = 12.1316 | ema=14.576\n",
            "Step 17 | loss = 15.5636 | ema=14.675\n",
            "Step 18 | loss = 13.3957 | ema=14.547\n",
            "Step 19 | loss = 17.9199 | ema=14.884\n",
            "Step 20 | loss = 13.0604 | ema=14.702\n",
            "Step 21 | loss = 12.1996 | ema=14.452\n",
            "Step 22 | loss = 17.3796 | ema=14.745\n",
            "Step 23 | loss = 10.8930 | ema=14.359\n",
            "Step 24 | loss = 12.4732 | ema=14.171\n",
            "Step 25 | loss = 12.2384 | ema=13.978\n",
            "Step 26 | loss = 19.7159 | ema=14.551\n",
            "Step 27 | loss = 13.4552 | ema=14.442\n",
            "Step 28 | loss = 26.8601 | ema=15.684\n",
            "Step 29 | loss = 10.5108 | ema=15.166\n",
            "Step 30 | loss = 15.2601 | ema=15.176\n",
            "Step 31 | loss = 12.0641 | ema=14.865\n",
            "Step 32 | loss = 11.8779 | ema=14.566\n",
            "Step 33 | loss = 10.2507 | ema=14.134\n",
            "Step 34 | loss = 10.8997 | ema=13.811\n",
            "Step 35 | loss = 14.6343 | ema=13.893\n",
            "Step 36 | loss = 17.8073 | ema=14.285\n",
            "Step 37 | loss = 9.6247 | ema=13.819\n",
            "Step 38 | loss = 16.5478 | ema=14.092\n",
            "Step 39 | loss = 19.0663 | ema=14.589\n",
            "Step 40 | loss = 12.2194 | ema=14.352\n",
            "Step 41 | loss = 12.1678 | ema=14.134\n",
            "Step 42 | loss = 7.4213 | ema=13.462\n",
            "Step 43 | loss = 17.3873 | ema=13.855\n",
            "Step 44 | loss = 10.8101 | ema=13.550\n",
            "Step 45 | loss = 8.3777 | ema=13.033\n",
            "Step 46 | loss = -0.0000 | ema=11.730\n",
            "Step 47 | loss = 19.4394 | ema=12.501\n",
            "Step 48 | loss = 15.7778 | ema=12.829\n",
            "Step 49 | loss = 12.5294 | ema=12.799\n",
            "\n",
            "Training expressive circuit with 4 layers\n",
            "Step 00 | loss = 12.7119 | ema=12.790\n",
            "Step 01 | loss = 8.6606 | ema=12.377\n",
            "Step 02 | loss = 13.0223 | ema=12.442\n",
            "Step 03 | loss = 12.7996 | ema=12.477\n",
            "Step 04 | loss = 20.5037 | ema=13.280\n",
            "Step 05 | loss = 8.8424 | ema=12.836\n",
            "Step 06 | loss = 12.6926 | ema=12.822\n",
            "Step 07 | loss = 8.8848 | ema=12.428\n",
            "Step 08 | loss = 15.1365 | ema=12.699\n",
            "Step 09 | loss = 21.5212 | ema=13.581\n",
            "Step 10 | loss = 14.8740 | ema=13.710\n",
            "Step 11 | loss = 14.5485 | ema=13.794\n",
            "Step 12 | loss = 13.0828 | ema=13.723\n",
            "Step 13 | loss = 11.3380 | ema=13.485\n",
            "Step 14 | loss = 8.5854 | ema=12.995\n",
            "Step 15 | loss = 13.4060 | ema=13.036\n",
            "Step 16 | loss = 14.1287 | ema=13.145\n",
            "Step 17 | loss = 14.1325 | ema=13.244\n",
            "Step 18 | loss = 6.4920 | ema=12.569\n",
            "Step 19 | loss = 25.8959 | ema=13.901\n",
            "Step 20 | loss = 16.4075 | ema=14.152\n",
            "Step 21 | loss = 8.9294 | ema=13.630\n",
            "Step 22 | loss = 8.1033 | ema=13.077\n",
            "Step 23 | loss = 16.8835 | ema=13.458\n",
            "Step 24 | loss = 4.4005 | ema=12.552\n",
            "Step 25 | loss = 9.3598 | ema=12.233\n",
            "Step 26 | loss = 24.9480 | ema=13.504\n",
            "Step 27 | loss = 13.4777 | ema=13.502\n",
            "Step 28 | loss = 11.6359 | ema=13.315\n",
            "Step 29 | loss = 17.8534 | ema=13.769\n",
            "Step 30 | loss = 6.4408 | ema=13.036\n",
            "Step 31 | loss = 11.9939 | ema=12.932\n",
            "Step 32 | loss = 19.8823 | ema=13.627\n",
            "Step 33 | loss = 20.3831 | ema=14.303\n",
            "Step 34 | loss = 10.1268 | ema=13.885\n",
            "Step 35 | loss = 10.7714 | ema=13.574\n",
            "Step 36 | loss = 18.0427 | ema=14.021\n",
            "Step 37 | loss = 14.1292 | ema=14.031\n",
            "Step 38 | loss = 14.9167 | ema=14.120\n",
            "Step 39 | loss = 10.5007 | ema=13.758\n",
            "Step 40 | loss = 16.5631 | ema=14.039\n",
            "Step 41 | loss = 14.1421 | ema=14.049\n",
            "Step 42 | loss = 15.7432 | ema=14.218\n",
            "Step 43 | loss = 18.6815 | ema=14.665\n",
            "Step 44 | loss = 21.0552 | ema=15.304\n",
            "Step 45 | loss = 14.3309 | ema=15.206\n",
            "Step 46 | loss = 13.1897 | ema=15.005\n",
            "Step 47 | loss = 11.4236 | ema=14.647\n",
            "Step 48 | loss = 18.5807 | ema=15.040\n",
            "Step 49 | loss = 14.5347 | ema=14.990\n",
            "\n",
            "Training expressive circuit with 6 layers\n",
            "Step 00 | loss = 9.8350 | ema=14.474\n",
            "Step 01 | loss = 15.0463 | ema=14.531\n",
            "Step 02 | loss = 12.2735 | ema=14.305\n",
            "Step 03 | loss = 7.5133 | ema=13.626\n",
            "Step 04 | loss = 10.6519 | ema=13.329\n",
            "Step 05 | loss = 14.8585 | ema=13.482\n",
            "Step 06 | loss = 13.0326 | ema=13.437\n",
            "Step 07 | loss = 12.8413 | ema=13.377\n",
            "Step 08 | loss = 20.0120 | ema=14.041\n",
            "Step 09 | loss = 18.8496 | ema=14.522\n",
            "Step 10 | loss = 16.1689 | ema=14.686\n",
            "Step 11 | loss = 17.8705 | ema=15.005\n",
            "Step 12 | loss = 10.0879 | ema=14.513\n",
            "Step 13 | loss = 6.7022 | ema=13.732\n",
            "Step 14 | loss = 15.4852 | ema=13.907\n",
            "Step 15 | loss = 19.0314 | ema=14.420\n",
            "Step 16 | loss = 22.8206 | ema=15.260\n",
            "Step 17 | loss = 11.0333 | ema=14.837\n",
            "Step 18 | loss = 17.8393 | ema=15.137\n",
            "Step 19 | loss = 9.2373 | ema=14.547\n",
            "Step 20 | loss = 10.8691 | ema=14.180\n",
            "Step 21 | loss = 13.1859 | ema=14.080\n",
            "Step 22 | loss = 14.7064 | ema=14.143\n",
            "Step 23 | loss = 16.3512 | ema=14.364\n",
            "Step 24 | loss = 11.7728 | ema=14.105\n",
            "Step 25 | loss = 15.5925 | ema=14.253\n",
            "Step 26 | loss = 18.9777 | ema=14.726\n",
            "Step 27 | loss = 18.4098 | ema=15.094\n",
            "Step 28 | loss = 17.3555 | ema=15.320\n",
            "Step 29 | loss = 16.0610 | ema=15.394\n",
            "Step 30 | loss = 18.2348 | ema=15.678\n",
            "Step 31 | loss = 15.0023 | ema=15.611\n",
            "Step 32 | loss = 12.8126 | ema=15.331\n",
            "Step 33 | loss = 19.1920 | ema=15.717\n",
            "Step 34 | loss = 24.5551 | ema=16.601\n",
            "Step 35 | loss = 6.6032 | ema=15.601\n",
            "Step 36 | loss = 15.6531 | ema=15.606\n",
            "Step 37 | loss = 17.5565 | ema=15.801\n",
            "Step 38 | loss = 13.3422 | ema=15.555\n",
            "Step 39 | loss = 11.2320 | ema=15.123\n",
            "Step 40 | loss = 14.9150 | ema=15.102\n",
            "Step 41 | loss = 16.9145 | ema=15.284\n",
            "Step 42 | loss = 10.6068 | ema=14.816\n",
            "Step 43 | loss = 15.3780 | ema=14.872\n",
            "Step 44 | loss = 14.2370 | ema=14.809\n",
            "Step 45 | loss = 10.7976 | ema=14.407\n",
            "Step 46 | loss = 12.3213 | ema=14.199\n",
            "Step 47 | loss = 11.2863 | ema=13.908\n",
            "Step 48 | loss = 13.7382 | ema=13.891\n",
            "Step 49 | loss = 22.7416 | ema=14.776\n",
            "\n",
            "Training expressive circuit with 8 layers\n",
            "Step 00 | loss = 16.2997 | ema=14.928\n",
            "Step 01 | loss = 13.1147 | ema=14.747\n",
            "Step 02 | loss = 12.8368 | ema=14.556\n",
            "Step 03 | loss = 8.1838 | ema=13.919\n",
            "Step 04 | loss = 11.4418 | ema=13.671\n",
            "Step 05 | loss = 13.5816 | ema=13.662\n",
            "Step 06 | loss = 14.3957 | ema=13.735\n",
            "Step 07 | loss = 8.7481 | ema=13.237\n",
            "Step 08 | loss = 11.2399 | ema=13.037\n",
            "Step 09 | loss = 12.2786 | ema=12.961\n",
            "Step 10 | loss = 11.8927 | ema=12.854\n",
            "Step 11 | loss = 9.6231 | ema=12.531\n",
            "Step 12 | loss = 18.6000 | ema=13.138\n",
            "Step 13 | loss = 10.0399 | ema=12.828\n",
            "Step 14 | loss = 10.9993 | ema=12.645\n",
            "Step 15 | loss = 11.6070 | ema=12.541\n",
            "Step 16 | loss = 10.4293 | ema=12.330\n",
            "Step 17 | loss = 15.8649 | ema=12.684\n",
            "Step 18 | loss = 11.9603 | ema=12.611\n",
            "Step 19 | loss = 22.8988 | ema=13.640\n",
            "Step 20 | loss = 10.0253 | ema=13.279\n",
            "Step 21 | loss = 17.6604 | ema=13.717\n",
            "Step 22 | loss = 11.8488 | ema=13.530\n",
            "Step 23 | loss = 11.7549 | ema=13.353\n",
            "Step 24 | loss = 16.8232 | ema=13.700\n",
            "Step 25 | loss = 11.2378 | ema=13.453\n",
            "Step 26 | loss = 10.3013 | ema=13.138\n",
            "Step 27 | loss = 10.7306 | ema=12.897\n",
            "Step 28 | loss = 19.9023 | ema=13.598\n",
            "Step 29 | loss = 11.0023 | ema=13.338\n",
            "Step 30 | loss = 16.7645 | ema=13.681\n",
            "Step 31 | loss = 9.4174 | ema=13.255\n",
            "Step 32 | loss = 14.4101 | ema=13.370\n",
            "Step 33 | loss = 11.8416 | ema=13.217\n",
            "Step 34 | loss = 10.7572 | ema=12.971\n",
            "Step 35 | loss = 14.5292 | ema=13.127\n",
            "Step 36 | loss = 9.8613 | ema=12.801\n",
            "Step 37 | loss = 11.5941 | ema=12.680\n",
            "Step 38 | loss = 10.4846 | ema=12.460\n",
            "Step 39 | loss = 8.0103 | ema=12.015\n",
            "Step 40 | loss = 13.4274 | ema=12.157\n",
            "Step 41 | loss = 13.5990 | ema=12.301\n",
            "Step 42 | loss = 16.3928 | ema=12.710\n",
            "Step 43 | loss = 15.6572 | ema=13.005\n",
            "Step 44 | loss = 7.4913 | ema=12.453\n",
            "Step 45 | loss = 16.4410 | ema=12.852\n",
            "Step 46 | loss = 11.5653 | ema=12.723\n",
            "Step 47 | loss = 15.3987 | ema=12.991\n",
            "Step 48 | loss = 11.9181 | ema=12.884\n",
            "Step 49 | loss = 9.8976 | ema=12.585\n",
            "\n",
            "Training expressive circuit with 10 layers\n",
            "Step 00 | loss = 16.9661 | ema=13.023\n",
            "Step 01 | loss = 16.4738 | ema=13.368\n",
            "Step 02 | loss = 15.2117 | ema=13.553\n",
            "Step 03 | loss = 16.4382 | ema=13.841\n",
            "Step 04 | loss = 19.8036 | ema=14.437\n",
            "Step 05 | loss = 17.7275 | ema=14.766\n",
            "Step 06 | loss = 13.2516 | ema=14.615\n",
            "Step 07 | loss = 14.0842 | ema=14.562\n",
            "Step 08 | loss = 15.8842 | ema=14.694\n",
            "Step 09 | loss = 11.0422 | ema=14.329\n",
            "Step 10 | loss = 15.0356 | ema=14.400\n",
            "Step 11 | loss = 10.2031 | ema=13.980\n",
            "Step 12 | loss = 14.9182 | ema=14.074\n",
            "Step 13 | loss = 16.5306 | ema=14.319\n",
            "Step 14 | loss = 14.0818 | ema=14.296\n",
            "Step 15 | loss = 7.3872 | ema=13.605\n",
            "Step 16 | loss = 10.3093 | ema=13.275\n",
            "Step 17 | loss = 22.4714 | ema=14.195\n",
            "Step 18 | loss = 5.2990 | ema=13.305\n",
            "Step 19 | loss = 11.5734 | ema=13.132\n",
            "Step 20 | loss = 20.5642 | ema=13.875\n",
            "Step 21 | loss = 17.5836 | ema=14.246\n",
            "Step 22 | loss = 3.1528 | ema=13.137\n",
            "Step 23 | loss = 16.9991 | ema=13.523\n",
            "Step 24 | loss = 16.0743 | ema=13.778\n",
            "Step 25 | loss = 14.7510 | ema=13.875\n",
            "Step 26 | loss = 9.6722 | ema=13.455\n",
            "Step 27 | loss = 5.3143 | ema=12.641\n",
            "Step 28 | loss = 7.8673 | ema=12.164\n",
            "Step 29 | loss = 13.6170 | ema=12.309\n",
            "Step 30 | loss = 12.7839 | ema=12.356\n",
            "Step 31 | loss = 10.9694 | ema=12.218\n",
            "Step 32 | loss = 21.5200 | ema=13.148\n",
            "Step 33 | loss = 10.4411 | ema=12.877\n",
            "Step 34 | loss = 19.7220 | ema=13.562\n",
            "Step 35 | loss = 13.5341 | ema=13.559\n",
            "Step 36 | loss = 18.5428 | ema=14.057\n",
            "Step 37 | loss = 6.0192 | ema=13.254\n",
            "Step 38 | loss = 15.2142 | ema=13.450\n",
            "Step 39 | loss = 19.4443 | ema=14.049\n",
            "Step 40 | loss = 15.7094 | ema=14.215\n",
            "Step 41 | loss = 19.3645 | ema=14.730\n",
            "Step 42 | loss = 18.0066 | ema=15.058\n",
            "Step 43 | loss = 15.5308 | ema=15.105\n",
            "Step 44 | loss = 14.2599 | ema=15.021\n",
            "Step 45 | loss = 23.3921 | ema=15.858\n",
            "Step 46 | loss = 12.1437 | ema=15.486\n",
            "Step 47 | loss = 6.4296 | ema=14.581\n",
            "Step 48 | loss = 15.9015 | ema=14.713\n",
            "Step 49 | loss = 9.9103 | ema=14.232\n",
            "\n",
            "Training expressive circuit with 12 layers\n",
            "Step 00 | loss = 16.6176 | ema=14.471\n",
            "Step 01 | loss = 14.5467 | ema=14.479\n",
            "Step 02 | loss = 21.0536 | ema=15.136\n",
            "Step 03 | loss = 17.3642 | ema=15.359\n",
            "Step 04 | loss = 11.9318 | ema=15.016\n",
            "Step 05 | loss = 25.4440 | ema=16.059\n",
            "Step 06 | loss = 19.5484 | ema=16.408\n",
            "Step 07 | loss = 4.7550 | ema=15.243\n",
            "Step 08 | loss = 11.7153 | ema=14.890\n",
            "Step 09 | loss = 12.4852 | ema=14.649\n",
            "Step 10 | loss = 13.3663 | ema=14.521\n",
            "Step 11 | loss = 15.0942 | ema=14.578\n",
            "Step 12 | loss = 12.0054 | ema=14.321\n",
            "Step 13 | loss = 15.3565 | ema=14.425\n",
            "Step 14 | loss = 10.0676 | ema=13.989\n",
            "Step 15 | loss = 21.4913 | ema=14.739\n",
            "Step 16 | loss = 20.5209 | ema=15.317\n",
            "Step 17 | loss = 14.2581 | ema=15.211\n",
            "Step 18 | loss = 14.9194 | ema=15.182\n",
            "Step 19 | loss = 16.8437 | ema=15.348\n",
            "Step 20 | loss = 16.3455 | ema=15.448\n",
            "Step 21 | loss = 24.2499 | ema=16.328\n",
            "Step 22 | loss = 10.8626 | ema=15.782\n",
            "Step 23 | loss = 17.0767 | ema=15.911\n",
            "Step 24 | loss = 16.9673 | ema=16.017\n",
            "Step 25 | loss = 14.1256 | ema=15.828\n",
            "Step 26 | loss = 15.0478 | ema=15.750\n",
            "Step 27 | loss = 19.7078 | ema=16.146\n",
            "Step 28 | loss = 10.4323 | ema=15.574\n",
            "Step 29 | loss = 20.9049 | ema=16.107\n",
            "Step 30 | loss = 22.2169 | ema=16.718\n",
            "Step 31 | loss = 5.5917 | ema=15.606\n",
            "Step 32 | loss = 20.2990 | ema=16.075\n",
            "Step 33 | loss = 8.5947 | ema=15.327\n",
            "Step 34 | loss = 11.5342 | ema=14.948\n",
            "Step 35 | loss = 13.7354 | ema=14.826\n",
            "Step 36 | loss = 5.2421 | ema=13.868\n",
            "Step 37 | loss = 15.3881 | ema=14.020\n",
            "Step 38 | loss = 14.4755 | ema=14.066\n",
            "Step 39 | loss = 5.8128 | ema=13.240\n",
            "Step 40 | loss = 6.1166 | ema=12.528\n",
            "Step 41 | loss = 22.7527 | ema=13.550\n",
            "Step 42 | loss = 11.4180 | ema=13.337\n",
            "Step 43 | loss = 5.1639 | ema=12.520\n",
            "Step 44 | loss = 7.8593 | ema=12.054\n",
            "Step 45 | loss = 16.3929 | ema=12.488\n",
            "Step 46 | loss = 10.0066 | ema=12.240\n",
            "Step 47 | loss = 15.1647 | ema=12.532\n",
            "Step 48 | loss = 19.9176 | ema=13.271\n",
            "Step 49 | loss = 16.4780 | ema=13.591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yFXHD8Mq--g"
      },
      "source": [
        "### Step 3: QJPEG Compression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7NmV1jvNoXOs"
      },
      "outputs": [],
      "source": [
        "def vectorization(img, Cr, Cc, renorm=False):\n",
        "    \"Vectorize the image into amplitude-encoding patches suitable for quantum circuits\"\n",
        "    # splitting the original image (Mr, Mc) into S equal-size patches of shape (Cr, Cc)\n",
        "    Mr, Mc = img.shape\n",
        "    assert Mr % Cr == 0 and Mc % Cc == 0\n",
        "    patches = (img.reshape(Mc//Cr, Cr, -1, Cc).swapaxes(1, 2).reshape(-1, Cr, Cc))\n",
        "    # 64 patches, (64, 64, 64) shape; S=64\n",
        "\n",
        "    # vectorize each patch and collect all in a (N, Cr*Cc) array\n",
        "    vect_patches = np.reshape(patches,  (patches.shape[0], Cr*Cc)) # (64, 4096)\n",
        "\n",
        "    # normalize each (Cr*Cc) vector to the intensity of the corresponding (Cr, Cc) patch\n",
        "    states = np.zeros((patches.shape[0], Cr*Cc)) # (64, 4096)\n",
        "    norm = np.zeros(patches.shape[0])\n",
        "\n",
        "    for idx in range(patches.shape[0]): # for each patch\n",
        "        # compute the sum of pixels intensities\n",
        "        norm[idx] = vect_patches[idx].sum()\n",
        "        if norm[idx] == 0:\n",
        "            # empty patch -> encode |0...0>\n",
        "            states[idx, 0] = 1.0\n",
        "            norm[idx] = 1.0\n",
        "            continue\n",
        "\n",
        "        # normalize the patch vector so that its entries sum is 1\n",
        "        tmp = vect_patches[idx] / norm[idx]\n",
        "        # take the element-wise square root of the normalized vector\n",
        "        states[idx] = np.sqrt(tmp)\n",
        "    if renorm == False:\n",
        "        norm = np.ones(patches.shape[0])\n",
        "    print(states[:10])\n",
        "\n",
        "    return states, norm # amplitudes, pixel intensities' sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Cw7qW3kDrB8g"
      },
      "outputs": [],
      "source": [
        "def qft_swaps(wires):\n",
        "    n = len(wires)\n",
        "    # apply QFT to all qubits\n",
        "    qml.QFT(wires=wires)\n",
        "    # add swaps to reverse qubit order!\n",
        "    for i in range(n // 2):\n",
        "        qml.SWAP(wires=[wires[i], wires[n - i - 1]])\n",
        "\n",
        "\n",
        "def iqft_swaps(wires):\n",
        "    n = len(wires)\n",
        "    # swaps again - BEFORE iqft\n",
        "    for i in reversed(range(n // 2)):\n",
        "        qml.SWAP(wires=[wires[i], wires[n-i-1]])\n",
        "    qml.adjoint(QFT)(wires=wires)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "usd8_SMXyc_Y"
      },
      "outputs": [],
      "source": [
        "def circuit_builder(states, n0, n2, shots):\n",
        "    ntilde = (n0 - n2) // 2\n",
        "    n1 = n0 - ntilde\n",
        "\n",
        "    qnodes = []\n",
        "\n",
        "    # define device with n0 qubits\n",
        "    dev = qml.device(device, wires=n0, shots=shots)\n",
        "\n",
        "    for idx in range(states.shape[0]):\n",
        "        # qnode to capture current input state\n",
        "        @qml.qnode(dev)\n",
        "        def circuit():\n",
        "            # print(\"State norm:\", np.linalg.norm(states[idx]))\n",
        "            # initializing the state (using AmplitudeEmbedding here, but I'm wondering if something else could work faster)\n",
        "            qml.AmplitudeEmbedding(states[idx], wires=range(n0), normalize=True)\n",
        "\n",
        "            # Hadamard on all n0 qubits\n",
        "            for w in range(n0):\n",
        "                qml.Hadamard(wires=w)\n",
        "\n",
        "            # apply QFT on all qubits\n",
        "            qft_swaps(wires=range(n0))\n",
        "\n",
        "            # apply IQFT on first n1 qubits\n",
        "            iqft_swaps(wires=range(n1))\n",
        "\n",
        "            # setting boundaries - Rule 2\n",
        "            discard_start = n0 // 2 - ntilde\n",
        "            discard_end = n0 // 2 - 1\n",
        "            discarded_qubits = set(range(discard_start, discard_end + 1))\n",
        "\n",
        "            # keep exactly n2 qubits for output\n",
        "            measured_qubits = list(range(n2))\n",
        "\n",
        "\n",
        "            # Hadamard on remaining qubits\n",
        "            for q in measured_qubits:\n",
        "                qml.Hadamard(wires=q)\n",
        "\n",
        "            # print(f'Measured qubits: {measured_qubits}')\n",
        "\n",
        "            return qml.probs(wires=measured_qubits)\n",
        "        qnodes.append(circuit)\n",
        "\n",
        "    return qnodes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f8Cb9jBbodtD"
      },
      "outputs": [],
      "source": [
        "def reconstruction(qnodes, n2, norm):\n",
        "    out_freq = np.zeros((len(qnodes), 2**n2))\n",
        "    for idx, qnode in enumerate(qnodes):\n",
        "        probs = qnode()\n",
        "        out_freq[idx] = qnode() * norm[idx]\n",
        "\n",
        "    return out_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RLE8xtDaofNH"
      },
      "outputs": [],
      "source": [
        "def devectorization(out_freq):\n",
        "    S = out_freq.shape[0]\n",
        "    nrow = int(np.sqrt(out_freq.shape[1])) # rows per patch\n",
        "    ncol = nrow\n",
        "\n",
        "    decoded_patches = np.reshape(out_freq,\\\n",
        "                      (out_freq.shape[0], nrow, ncol)) # (S, nrow, ncol)\n",
        "\n",
        "    im_h, im_w = nrow*int(np.sqrt(S)), ncol*int(np.sqrt(S)) # final shape\n",
        "\n",
        "    # initialization\n",
        "    decoded_img = np.zeros((im_w, im_h))\n",
        "\n",
        "    idx = 0\n",
        "    for row in np.arange(im_h - nrow + 1, step=nrow):\n",
        "        for col in np.arange(im_w - ncol + 1, step=ncol):\n",
        "            decoded_img[row:row+nrow, col:col+ncol] = decoded_patches[idx]\n",
        "            idx += 1\n",
        "\n",
        "    return decoded_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nfA2v4IoTpE0"
      },
      "outputs": [],
      "source": [
        "def qjpeg_feature_map_quantum(img_28x28):\n",
        "    \"\"\"\n",
        "    True QJPEG-inspired feature map:\n",
        "    - probabilities sum to 1\n",
        "    - amplitudes = sqrt(probabilities)\n",
        "    - output dimension = 64 (6 qubits)\n",
        "    \"\"\"\n",
        "\n",
        "    img = img_28x28.astype(float)\n",
        "    img = img / img.sum()              # probabilities\n",
        "    amps = np.sqrt(img.flatten())      # amplitudes\n",
        "\n",
        "    # reduce to 64 amplitudes (simple truncation for now)\n",
        "    amps = amps[:64]\n",
        "\n",
        "    # safety\n",
        "    if np.linalg.norm(amps) == 0:\n",
        "        amps[0] = 1.0\n",
        "    else:\n",
        "        amps /= np.linalg.norm(amps)\n",
        "\n",
        "    return amps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J-NBBmzuDeb"
      },
      "source": [
        "### Step 4: Inference without retraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nVgx9d3ORmuO"
      },
      "outputs": [],
      "source": [
        "C = 1.0\n",
        "layers_list = [2, 4, 6, 8, 10, 12]\n",
        "\n",
        "# --- Devices and QNodes ---\n",
        "dev = qml.device(device, wires=n_qubits, shots=None)\n",
        "\n",
        "# Expressive circuit QNode\n",
        "qnode_expressive = qml.QNode(feature_map, dev)\n",
        "\n",
        "n_layers_max = max(layers_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "-B37izfjljyl"
      },
      "outputs": [],
      "source": [
        "def combine_qek_qjpeg(x_qek, x_qjpeg):\n",
        "    \"\"\"Combine first 32 QEK amplitudes + full QJPEG vector, then normalize.\"\"\"\n",
        "    v = np.concatenate([x_qek[:32], x_qjpeg])\n",
        "    norm = np.linalg.norm(v)\n",
        "    if norm == 0:\n",
        "        return v\n",
        "    return v / norm\n",
        "\n",
        "def compute_kernel(states_a, states_b=None):\n",
        "    \"\"\"Compute quantum kernel matrix from states.\"\"\"\n",
        "    if states_b is None:\n",
        "        states_b = states_a\n",
        "    K = np.zeros((len(states_a), len(states_b)))\n",
        "    for i, a in enumerate(states_a):\n",
        "        for j, b in enumerate(states_b):\n",
        "            K[i,j] = np.abs(np.vdot(a, b))**2\n",
        "    return K\n",
        "\n",
        "def evaluate_kernel(qnode, theta, X_train, X_test, y_train, y_test, C=1.0):\n",
        "    \"\"\"Compute kernel, train SVM with precomputed kernel, and return test accuracy.\"\"\"\n",
        "    # Compute states\n",
        "    states_train = np.array([qnode(x, theta) for x in X_train])\n",
        "    states_test  = np.array([qnode(x, theta) for x in X_test])\n",
        "\n",
        "    # Kernel computation with safe normalization\n",
        "    K_train = compute_kernel(states_train)\n",
        "    max_val = np.max(K_train)\n",
        "    if max_val == 0:\n",
        "        max_val = 1.0\n",
        "    K_train /= max_val\n",
        "\n",
        "    K_test = compute_kernel(states_test, states_train)\n",
        "    K_test /= max_val\n",
        "\n",
        "    # Train SVM\n",
        "    clf = SVC(kernel=\"precomputed\", C=C)\n",
        "    clf.fit(K_train, y_train)\n",
        "\n",
        "    # Predict and return accuracy\n",
        "    y_pred = clf.predict(K_test)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "def qjpeg_to_32(img_28x28):\n",
        "    \"\"\"Return 32-dimensional QJPEG vector from 28x28 image.\"\"\"\n",
        "    amps = qjpeg_feature_map_quantum(img_28x28)  # get 64 amplitudes\n",
        "    amps_32 = amps[:32]  # truncate to 32\n",
        "    norm = np.linalg.norm(amps_32)\n",
        "    if norm == 0:\n",
        "        amps_32[0] = 1.0\n",
        "        norm = 1.0\n",
        "    return amps_32 / norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bZl3fxk51sgz"
      },
      "outputs": [],
      "source": [
        "# --- Prepare QJPEG 32-dimensional vectors ---\n",
        "X_train_qjpeg = np.array([qjpeg_to_32(img.reshape(28,28)) for img in X_train_img])\n",
        "X_test_qjpeg  = np.array([qjpeg_to_32(img.reshape(28,28)) for img in X_test_img])\n",
        "\n",
        "# --- Prepare combined QEK + QJPEG vectors ---\n",
        "X_train_combined = np.array([\n",
        "    combine_qek_qjpeg(a, b) for a, b in zip(X_train_qek, X_train_qjpeg)\n",
        "])\n",
        "X_test_combined = np.array([\n",
        "    combine_qek_qjpeg(a, b) for a, b in zip(X_test_qek, X_test_qjpeg)\n",
        "])\n",
        "\n",
        "# --- Random initial theta for expressive circuit ---\n",
        "theta_base = np.random.uniform(\n",
        "    0, 2*np.pi, size=(max(layers_list), n_qubits, 3)\n",
        ")\n",
        "\n",
        "# --- Evaluate circuits ---\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tDMyosyx-vi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b299de-2d53-4669-c3e1-abecc9f0efae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Evaluating expressive circuit with 2 layers\n",
            "========================================\n",
            "QEK accuracy:         0.9000\n",
            "QEK + QJPEG accuracy: 0.9000\n",
            "\n",
            "========================================\n",
            "Evaluating expressive circuit with 4 layers\n",
            "========================================\n",
            "QEK accuracy:         0.9000\n",
            "QEK + QJPEG accuracy: 0.9000\n",
            "\n",
            "========================================\n",
            "Evaluating expressive circuit with 6 layers\n",
            "========================================\n",
            "QEK accuracy:         0.9000\n",
            "QEK + QJPEG accuracy: 0.9000\n",
            "\n",
            "========================================\n",
            "Evaluating expressive circuit with 8 layers\n",
            "========================================\n",
            "QEK accuracy:         0.9000\n",
            "QEK + QJPEG accuracy: 0.9000\n",
            "\n",
            "========================================\n",
            "Evaluating expressive circuit with 10 layers\n",
            "========================================\n",
            "QEK accuracy:         0.9000\n",
            "QEK + QJPEG accuracy: 0.9000\n",
            "\n",
            "========================================\n",
            "Evaluating expressive circuit with 12 layers\n",
            "========================================\n",
            "QEK accuracy:         0.9000\n",
            "QEK + QJPEG accuracy: 0.9000\n"
          ]
        }
      ],
      "source": [
        "for layers_count in layers_list:\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Evaluating expressive circuit with {layers_count} layers\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Define a QNode that returns the state vector\n",
        "    @qml.qnode(dev)\n",
        "    def expressive_state_qnode(x, current_theta):\n",
        "        feature_map(x, current_theta)\n",
        "        return qml.state()\n",
        "\n",
        "    # Use theta_base for different numbers of layers, slicing it\n",
        "    current_theta_params = theta_base[:layers_count]\n",
        "\n",
        "    # QEK only\n",
        "    acc_qek = evaluate_kernel(\n",
        "        expressive_state_qnode,\n",
        "        current_theta_params,\n",
        "        X_train_qek,\n",
        "        X_test_qek,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        C=C\n",
        "    )\n",
        "    print(f\"QEK accuracy:         {acc_qek:.4f}\")\n",
        "\n",
        "    # QEK + QJPEG combined\n",
        "    acc_combined = evaluate_kernel(\n",
        "        expressive_state_qnode,\n",
        "        current_theta_params,\n",
        "        X_train_combined,\n",
        "        X_test_combined,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        C=C\n",
        "    )\n",
        "    print(f\"QEK + QJPEG accuracy: {acc_combined:.4f}\")\n",
        "\n",
        "    results.append((layers_count, acc_qek, acc_combined))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "U0F6HK86DJYH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KROFpzJsoxfN",
        "LPeJfiDJo-qn",
        "5yFXHD8Mq--g"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}