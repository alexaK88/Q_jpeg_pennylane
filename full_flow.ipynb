{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexaK88/Q_jpeg_pennylane/blob/main/full_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nrVJJ9YHoiPh",
        "outputId": "40e308af-5a2d-47c2-d53a-0c492d93a452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.44.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.2 (from pennylane)\n",
            "  Downloading autoray-0.8.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.4)\n",
            "Collecting pennylane-lightning>=0.44 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.44->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.31.22.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.44.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.2-py3-none-any.whl (935 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.31.22.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.2 diastatic-malt-2.15.2 pennylane-0.44.0 pennylane-lightning-0.44.0 rustworkx-0.17.1 scipy-openblas32-0.3.31.22.0\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: pennylane-lightning[gpu] in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray==0.8.2 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning[gpu]) (0.3.31.22.0)\n",
            "Collecting pennylane-lightning-gpu (from pennylane-lightning[gpu])\n",
            "  Downloading pennylane_lightning_gpu-0.44.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Collecting custatevec-cu12 (from pennylane-lightning-gpu->pennylane-lightning[gpu])\n",
            "  Downloading custatevec_cu12-1.12.0-py3-none-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from pennylane-lightning-gpu->pennylane-lightning[gpu])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from pennylane-lightning-gpu->pennylane-lightning[gpu])\n",
            "  Downloading nvidia_cusparse_cu12-12.5.10.65-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12 (from pennylane-lightning-gpu->pennylane-lightning[gpu])\n",
            "  Downloading nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12 (from pennylane-lightning-gpu->pennylane-lightning[gpu])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane_lightning_gpu-0.44.0-cp312-cp312-manylinux_2_28_x86_64.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.3/913.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading custatevec_cu12-1.12.0-py3-none-manylinux2014_x86_64.whl (73.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl (581.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.2/581.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.10.65-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (366.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.5/366.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: custatevec-cu12, nvidia-nvjitlink-cu12, nvidia-cuda-runtime-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, pennylane-lightning-gpu\n",
            "Successfully installed custatevec-cu12-1.12.0 nvidia-cublas-cu12-12.9.1.4 nvidia-cuda-runtime-cu12-12.9.79 nvidia-cusparse-cu12-12.5.10.65 nvidia-nvjitlink-cu12-12.9.86 pennylane-lightning-gpu-0.44.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane\n",
        "!pip install pennylane pennylane-lightning[gpu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KROFpzJsoxfN"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-JpS4QpoxBj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pennylane as qml\n",
        "from pennylane.templates import QFT\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import fetch_openml, load_digits\n",
        "from sklearn.preprocessing import MinMaxScaler, normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from pennylane import numpy as pnp\n",
        "from skimage.transform import resize\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPeJfiDJo-qn"
      },
      "source": [
        "### Step 1:  Dataset Preparation\n",
        "\n",
        "* Load MIST dataset - 0/1 pixel intensities\n",
        "* Reduce image to 8x8\n",
        "    * Resizing using skimage\n",
        "    * Crop and pad (zero-padding)\n",
        "* Normalize all images:\n",
        "  8x8 image -> flatten -> vector of length 64 -> normalize\n",
        "* Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amm-B8_Xdzyf"
      },
      "outputs": [],
      "source": [
        "# loading mnist from openML\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist['data'].astype(np.uint8) # better to convert for binerization\n",
        "y = mnist['target'].astype(np.uint8)\n",
        "y = y.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeMOrBB2ognh"
      },
      "source": [
        "Here, I've been experimenting with different classes, and I stopped on 4 vs 9, cause they have more subtle difference in pixels, they are similar looking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNShS1qTpNI7",
        "outputId": "743e2d46-8759-4943-e006-4d17d9cecf9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13782, 784)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# focus on binary classification\n",
        "mask = (y == 4) | (y == 9)\n",
        "X, y = X[mask], y[mask]\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GdbQMsOdpoWz"
      },
      "outputs": [],
      "source": [
        "n_samples = 100 # restricting to 6000 samples for now\n",
        "\n",
        "X = X.values if hasattr(X, \"values\") else X # safer conversion\n",
        "perm = np.random.permutation(len(X))\n",
        "X, y = X[perm], y[perm]\n",
        "\n",
        "X = X[:n_samples]\n",
        "y = y[:n_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFV8_UnGptzJ"
      },
      "source": [
        "Normalise pixel intensities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A69wNTvdppCb",
        "outputId": "5b222eb2-93c2-4b95-e914-a10216bc775e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 28, 28)\n",
            "Pixel range: 0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "X = X / 255.0\n",
        "X = X.reshape(-1, 28, 28)\n",
        "\n",
        "print(X.shape)\n",
        "print(\"Pixel range:\", X.min(), X.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6fKM38QpyO8"
      },
      "source": [
        "Reducing images to 8x8 + flattening to (, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXfPx1nwpq31",
        "outputId": "6921a2ca-7d71-44a5-9bad-a0bd3286817c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 64)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert each 28x28 binarised image to 8x8, then flatten to length 64\n",
        "def to_8x8_vector(img_row):\n",
        "    img_8x8 = resize(\n",
        "        img_row,\n",
        "        (8, 8),\n",
        "        anti_aliasing=False,\n",
        "        preserve_range=True,\n",
        "        order=1 # controlling interpolation\n",
        "    )\n",
        "    img_8x8 = img_8x8.flatten()\n",
        "    s = np.sum(img_8x8)\n",
        "\n",
        "    if s > 0:\n",
        "        img_8x8 = np.sqrt(img_8x8 / s)\n",
        "    else:\n",
        "        img_8x8 = np.zeros_like(img_8x8)\n",
        "        img_8x8[0] = 1.0\n",
        "      # should be shape (64,)\n",
        "    return img_8x8\n",
        "\n",
        "# apply to all images\n",
        "X_8x8 = np.array([to_8x8_vector(x) for x in X], dtype=float)\n",
        "X_8x8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycrMsoOtp2BY",
        "outputId": "741fcf6c-a4c8-4e8f-8d88-cda53399b41a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Any NaNs? False\n",
            "Norm check: 0.9999999999999999 1.0\n"
          ]
        }
      ],
      "source": [
        "# def safe_l2_normalize_rows(X):\n",
        "#     norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
        "#     norms[norms == 0] = 1.0\n",
        "#     return X / norms\n",
        "\n",
        "# X_8x8_norm = safe_l2_normalize_rows(X_8x8)\n",
        "print(\"Any NaNs?\", np.isnan(X_8x8).any())\n",
        "print(\"Norm check:\", np.min(np.linalg.norm(X_8x8, axis=1)), np.max(np.linalg.norm(X_8x8, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUuSiBQfp_Sf"
      },
      "source": [
        "I'm gonna do the splitting here, and carry both representations consistently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbFUj8-Zp9fc",
        "outputId": "6489c151-9a92-4598-aab5-b27cbd1a2f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QEK train/test: (80, 64) (20, 64)\n",
            "IMG train/test: (80, 28, 28) (20, 28, 28)\n",
            "Labels train/test: (80,) (20,)\n"
          ]
        }
      ],
      "source": [
        "idx = np.arange(n_samples)\n",
        "\n",
        "idx_train, idx_test, y_train, y_test = train_test_split(\n",
        "    idx, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# QEK inputs (8x8 -> 64 -> normed)\n",
        "X_train_qek = X_8x8[idx_train]\n",
        "X_test_qek  = X_8x8[idx_test]\n",
        "\n",
        "# QJPEG inputs (28x28 binary images)\n",
        "X_train_img = X[idx_train]\n",
        "X_test_img  = X[idx_test]\n",
        "\n",
        "print(\"QEK train/test:\", X_train_qek.shape, X_test_qek.shape)\n",
        "print(\"IMG train/test:\", X_train_img.shape, X_test_img.shape)\n",
        "print(\"Labels train/test:\", y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQUmF-0YqOjS"
      },
      "source": [
        "Data preparation is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxklKVp_qRRT"
      },
      "source": [
        "### Step 2: Quantum Embedding & Kernel Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDnTjviKqYmk"
      },
      "outputs": [],
      "source": [
        "n_qubits = 6\n",
        "layers = 2\n",
        "wires = range(n_qubits)\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=wires, shots=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54-8ETQgqrnD"
      },
      "source": [
        "Defining QEK circuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vcR07EVnqp_8"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def kernel_qnode(x1, x2, theta):\n",
        "    # Prepare |ψ(x1, θ)>\n",
        "    qml.AmplitudeEmbedding(x1, wires=wires, normalize=False)\n",
        "\n",
        "    for l in range(theta.shape[0]):\n",
        "        for i in range(n_qubits):\n",
        "            qml.RX(theta[l, i, 0], wires=i)\n",
        "            qml.RY(theta[l, i, 1], wires=i)\n",
        "            qml.RZ(theta[l, i, 2], wires=i)\n",
        "        for i in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i + 1])\n",
        "\n",
        "    # Apply adjoint of |ψ(x2, θ)>\n",
        "    qml.adjoint(\n",
        "        lambda: (\n",
        "            qml.AmplitudeEmbedding(x2, wires=wires, normalize=False),\n",
        "            *[\n",
        "                (\n",
        "                    qml.RX(theta[l, i, 0], wires=i),\n",
        "                    qml.RY(theta[l, i, 1], wires=i),\n",
        "                    qml.RZ(theta[l, i, 2], wires=i),\n",
        "                )\n",
        "                for l in range(theta.shape[0])\n",
        "                for i in range(n_qubits)\n",
        "            ],\n",
        "        )\n",
        "    )()\n",
        "\n",
        "    # Probability of |00...0>\n",
        "    return qml.expval(qml.Projector([0]*n_qubits, wires=wires))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 1: train for 12 layers (max)\n",
        "option 2: train for every number of layers"
      ],
      "metadata": {
        "id": "pDPL5tLxWMka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtTvYKYRXqLO"
      },
      "outputs": [],
      "source": [
        "n_qubits = 6\n",
        "n_layers = 12          # number of trainable layers\n",
        "layers = n_layers     # just to match variable names\n",
        "batch_size = 12       # bigger batch for stability\n",
        "n_steps = 50          # training steps\n",
        "stepsize = 0.03       # smaller learning rate\n",
        "eps_trace = 1e-8      # small epsilon to prevent division by zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "07tRKk_SfEFc",
        "collapsed": true,
        "outputId": "66ee20f1-46e4-4375-9b8a-2f850dc3b9f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: loss = 0.1986\n",
            "Step 1: loss = -0.4314\n",
            "Step 2: loss = -0.0951\n",
            "Step 3: loss = -0.0373\n",
            "Step 4: loss = -0.4019\n",
            "Step 5: loss = -0.4277\n",
            "Step 6: loss = 0.0666\n",
            "Step 7: loss = -0.3945\n",
            "Step 8: loss = -0.2587\n",
            "Step 9: loss = -0.3509\n",
            "Step 10: loss = -0.4265\n",
            "Step 11: loss = -0.5087\n",
            "Step 12: loss = -0.2736\n",
            "Step 13: loss = -0.4796\n",
            "Step 14: loss = -0.3496\n",
            "Step 15: loss = -0.3384\n",
            "Step 16: loss = -0.3967\n",
            "Step 17: loss = -0.5174\n",
            "Step 18: loss = -0.2765\n",
            "Step 19: loss = -0.2947\n",
            "Step 20: loss = -0.6961\n",
            "Step 21: loss = -0.2812\n",
            "Step 22: loss = -0.5482\n",
            "Step 23: loss = -0.4198\n",
            "Step 24: loss = -0.4469\n",
            "Step 25: loss = -0.7151\n",
            "Step 26: loss = -0.3548\n",
            "Step 27: loss = -0.2621\n",
            "Step 28: loss = -0.4884\n",
            "Step 29: loss = -0.6333\n",
            "Step 30: loss = -0.3736\n",
            "Step 31: loss = -0.0885\n",
            "Step 32: loss = -0.5347\n",
            "Step 33: loss = -0.2266\n",
            "Step 34: loss = -0.5045\n",
            "Step 35: loss = -0.4552\n",
            "Step 36: loss = -0.3319\n",
            "Step 37: loss = -0.7508\n",
            "Step 38: loss = -0.7840\n",
            "Step 39: loss = -0.7106\n",
            "Step 40: loss = -0.6601\n",
            "Step 41: loss = -0.6127\n",
            "Step 42: loss = -0.7187\n",
            "Step 43: loss = -0.3017\n",
            "Step 44: loss = -0.1493\n",
            "Step 45: loss = -0.4564\n",
            "Step 46: loss = -0.7635\n",
            "Step 47: loss = -0.6397\n",
            "Step 48: loss = -0.5815\n",
            "Step 49: loss = -0.6187\n"
          ]
        }
      ],
      "source": [
        "def kernel_matrix(X1, X2, theta):\n",
        "    return qml.math.stack([\n",
        "        qml.math.stack([\n",
        "            kernel_qnode(x1, x2, theta)\n",
        "            for x2 in X2\n",
        "        ])\n",
        "        for x1 in X1\n",
        "    ])\n",
        "\n",
        "\n",
        "# --- Kernel alignment loss (batch) ---\n",
        "def kernel_alignment_loss_batch(theta, X, y, batch_size=6):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    Xb = X[idx]\n",
        "    yb = y[idx]\n",
        "\n",
        "    # Kernel\n",
        "    K = kernel_matrix(Xb, Xb, theta)\n",
        "\n",
        "    # Labels: ±1\n",
        "    y_pm = 2 * (yb == 9) - 1\n",
        "    yy = qml.math.outer(y_pm, y_pm)\n",
        "\n",
        "    # Center kernel\n",
        "    n = batch_size\n",
        "    H = qml.math.eye(n) - qml.math.ones((n, n)) / n\n",
        "    Kc = H @ K @ H\n",
        "\n",
        "    # Flatten\n",
        "    Kf = qml.math.reshape(Kc, (-1,))\n",
        "    yyf = qml.math.reshape(yy, (-1,))\n",
        "\n",
        "    # Alignment = ⟨Kc, yy⟩ / (||Kc|| ||yy||)\n",
        "    numerator = qml.math.dot(Kf, yyf)\n",
        "    denominator = qml.math.sqrt(\n",
        "        qml.math.dot(Kf, Kf) * qml.math.dot(yyf, yyf)\n",
        "    )\n",
        "\n",
        "    return -numerator / denominator\n",
        "\n",
        "\n",
        "opt = qml.AdamOptimizer(stepsize=stepsize)\n",
        "\n",
        "theta = 0.01 * pnp.random.randn(n_layers, n_qubits, 3, requires_grad=True)\n",
        "\n",
        "def loss_fn(theta):\n",
        "    return kernel_alignment_loss_batch(theta, X_train_qek, y_train, batch_size)\n",
        "\n",
        "for step in range(n_steps):\n",
        "    theta, loss = opt.step_and_cost(loss_fn, theta)\n",
        "    print(f\"Step {step}: loss = {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_trained = theta\n",
        "np.save(\"theta_trained.npy\", theta_trained)"
      ],
      "metadata": {
        "id": "_0J0IHRtQrjQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdMqnQSn1fyq",
        "outputId": "42ac70d9-2085-4f6e-a420-ded4ccd572e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.5908546858257661 0.327879369344936\n"
          ]
        }
      ],
      "source": [
        "loss_trained = loss_fn(theta)\n",
        "loss_zero = loss_fn(np.zeros_like(theta))\n",
        "\n",
        "print(loss_trained, loss_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H-MLB1XFmm12",
        "outputId": "ef602e2a-ac8f-42bb-8a25-9ea1fe8faffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.6426051027477397\n",
            "0.11839052982375203\n"
          ]
        }
      ],
      "source": [
        "theta_zero = np.zeros_like(theta)\n",
        "print(kernel_alignment_loss_batch(theta, X_train_qek, y_train, batch_size=16))\n",
        "print(kernel_alignment_loss_batch(theta_zero, X_train_qek, y_train, batch_size=16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yFXHD8Mq--g"
      },
      "source": [
        "### Step 3: QJPEG Compression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7NmV1jvNoXOs"
      },
      "outputs": [],
      "source": [
        "def vectorization(img, Cr, Cc, renorm=False):\n",
        "    \"Vectorize the image into amplitude-encoding patches suitable for quantum circuits\"\n",
        "    # splitting the original image (Mr, Mc) into S equal-size patches of shape (Cr, Cc)\n",
        "    Mr, Mc = img.shape\n",
        "    assert Mr % Cr == 0 and Mc % Cc == 0\n",
        "    patches = (img.reshape(Mc//Cr, Cr, -1, Cc).swapaxes(1, 2).reshape(-1, Cr, Cc))\n",
        "    # 64 patches, (64, 64, 64) shape; S=64\n",
        "\n",
        "    # vectorize each patch and collect all in a (N, Cr*Cc) array\n",
        "    vect_patches = np.reshape(patches,  (patches.shape[0], Cr*Cc)) # (64, 4096)\n",
        "\n",
        "    # normalize each (Cr*Cc) vector to the intensity of the corresponding (Cr, Cc) patch\n",
        "    states = np.zeros((patches.shape[0], Cr*Cc)) # (64, 4096)\n",
        "    norm = np.zeros(patches.shape[0])\n",
        "\n",
        "    for idx in range(patches.shape[0]): # for each patch\n",
        "        # compute the sum of pixels intensities\n",
        "        norm[idx] = vect_patches[idx].sum()\n",
        "        if norm[idx] == 0:\n",
        "            # empty patch -> encode |0...0>\n",
        "            states[idx, 0] = 1.0\n",
        "            norm[idx] = 1.0\n",
        "            continue\n",
        "\n",
        "        # normalize the patch vector so that its entries sum is 1\n",
        "        tmp = vect_patches[idx] / norm[idx]\n",
        "        # take the element-wise square root of the normalized vector\n",
        "        states[idx] = np.sqrt(tmp)\n",
        "    if renorm == False:\n",
        "        norm = np.ones(patches.shape[0])\n",
        "    print(states[:10])\n",
        "\n",
        "    return states, norm # amplitudes, pixel intensities' sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cw7qW3kDrB8g"
      },
      "outputs": [],
      "source": [
        "def qft_swaps(wires):\n",
        "    n = len(wires)\n",
        "    # apply QFT to all qubits\n",
        "    qml.QFT(wires=wires)\n",
        "    # add swaps to reverse qubit order!\n",
        "    for i in range(n // 2):\n",
        "        qml.SWAP(wires=[wires[i], wires[n - i - 1]])\n",
        "\n",
        "\n",
        "def iqft_swaps(wires):\n",
        "    n = len(wires)\n",
        "    # swaps again - BEFORE iqft\n",
        "    for i in reversed(range(n // 2)):\n",
        "        qml.SWAP(wires=[wires[i], wires[n-i-1]])\n",
        "    qml.adjoint(QFT)(wires=wires)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "usd8_SMXyc_Y"
      },
      "outputs": [],
      "source": [
        "def circuit_builder(states, n0, n2, shots):\n",
        "    ntilde = (n0 - n2) // 2\n",
        "    n1 = n0 - ntilde\n",
        "\n",
        "    qnodes = []\n",
        "\n",
        "    # define device with n0 qubits\n",
        "    dev = qml.device(\"lightning.qubit\", wires=n0, shots=shots)\n",
        "\n",
        "    for idx in range(states.shape[0]):\n",
        "        # qnode to capture current input state\n",
        "        @qml.qnode(dev)\n",
        "        def circuit():\n",
        "            # print(\"State norm:\", np.linalg.norm(states[idx]))\n",
        "            # initializing the state (using AmplitudeEmbedding here, but I'm wondering if something else could work faster)\n",
        "            qml.AmplitudeEmbedding(states[idx], wires=range(n0), normalize=True)\n",
        "\n",
        "            # Hadamard on all n0 qubits\n",
        "            for w in range(n0):\n",
        "                qml.Hadamard(wires=w)\n",
        "\n",
        "            # apply QFT on all qubits\n",
        "            qft_swaps(wires=range(n0))\n",
        "\n",
        "            # apply IQFT on first n1 qubits\n",
        "            iqft_swaps(wires=range(n1))\n",
        "\n",
        "            # setting boundaries - Rule 2\n",
        "            discard_start = n0 // 2 - ntilde\n",
        "            discard_end = n0 // 2 - 1\n",
        "            discarded_qubits = set(range(discard_start, discard_end + 1))\n",
        "\n",
        "            # keep exactly n2 qubits for output\n",
        "            measured_qubits = list(range(n2))\n",
        "\n",
        "\n",
        "            # Hadamard on remaining qubits\n",
        "            for q in measured_qubits:\n",
        "                qml.Hadamard(wires=q)\n",
        "\n",
        "            # print(f'Measured qubits: {measured_qubits}')\n",
        "\n",
        "            return qml.probs(wires=measured_qubits)\n",
        "        qnodes.append(circuit)\n",
        "\n",
        "    return qnodes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f8Cb9jBbodtD"
      },
      "outputs": [],
      "source": [
        "def reconstruction(qnodes, n2, norm):\n",
        "    out_freq = np.zeros((len(qnodes), 2**n2))\n",
        "    for idx, qnode in enumerate(qnodes):\n",
        "        probs = qnode()\n",
        "        out_freq[idx] = qnode() * norm[idx]\n",
        "\n",
        "    return out_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RLE8xtDaofNH"
      },
      "outputs": [],
      "source": [
        "def devectorization(out_freq):\n",
        "    S = out_freq.shape[0]\n",
        "    nrow = int(np.sqrt(out_freq.shape[1])) # rows per patch\n",
        "    ncol = nrow\n",
        "\n",
        "    decoded_patches = np.reshape(out_freq,\\\n",
        "                      (out_freq.shape[0], nrow, ncol)) # (S, nrow, ncol)\n",
        "\n",
        "    im_h, im_w = nrow*int(np.sqrt(S)), ncol*int(np.sqrt(S)) # final shape\n",
        "\n",
        "    # initialization\n",
        "    decoded_img = np.zeros((im_w, im_h))\n",
        "\n",
        "    idx = 0\n",
        "    for row in np.arange(im_h - nrow + 1, step=nrow):\n",
        "        for col in np.arange(im_w - ncol + 1, step=ncol):\n",
        "            decoded_img[row:row+nrow, col:col+ncol] = decoded_patches[idx]\n",
        "            idx += 1\n",
        "\n",
        "    return decoded_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nfA2v4IoTpE0"
      },
      "outputs": [],
      "source": [
        "def qjpeg_feature_map_quantum(img_28x28):\n",
        "    \"\"\"\n",
        "    True QJPEG-inspired feature map:\n",
        "    - probabilities sum to 1\n",
        "    - amplitudes = sqrt(probabilities)\n",
        "    - output dimension = 64 (6 qubits)\n",
        "    \"\"\"\n",
        "\n",
        "    img = img_28x28.astype(float)\n",
        "    img = img / img.sum()              # probabilities\n",
        "    amps = np.sqrt(img.flatten())      # amplitudes\n",
        "\n",
        "    # reduce to 64 amplitudes (simple truncation for now)\n",
        "    amps = amps[:64]\n",
        "\n",
        "    # safety\n",
        "    if np.linalg.norm(amps) == 0:\n",
        "        amps[0] = 1.0\n",
        "    else:\n",
        "        amps /= np.linalg.norm(amps)\n",
        "\n",
        "    return amps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J-NBBmzuDeb"
      },
      "source": [
        "### Step 4: Inference without retraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nVgx9d3ORmuO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "C = 1.0\n",
        "layers_list = [2, 4, 6, 8, 10, 12]\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=None)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode_state(x, theta):\n",
        "    kernel_qnode(x, theta)\n",
        "    return qml.state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "-B37izfjljyl"
      },
      "outputs": [],
      "source": [
        "def compute_kernel(states_a, states_b=None):\n",
        "    if states_b is None:\n",
        "        states_b = states_a\n",
        "    K = np.zeros((len(states_a), len(states_b)))\n",
        "    for i, a in enumerate(states_a):\n",
        "        for j, b in enumerate(states_b):\n",
        "            K[i, j] = np.abs(np.vdot(a, b))**2\n",
        "    return K\n",
        "\n",
        "def evaluate_kernel_inference(\n",
        "    qnode,\n",
        "    theta,\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    C=1.0,\n",
        "):\n",
        "    # 1. Compute quantum states\n",
        "    states_train = np.array([qnode(x, theta) for x in X_train])\n",
        "    states_test  = np.array([qnode(x, theta) for x in X_test])\n",
        "\n",
        "    # 2. Kernel matrices\n",
        "    K_train = compute_kernel(states_train)\n",
        "    K_test  = compute_kernel(states_test, states_train)\n",
        "\n",
        "    # 3. Normalize (important for SVM stability)\n",
        "    max_val = np.max(K_train)\n",
        "    if max_val > 0:\n",
        "        K_train /= max_val\n",
        "        K_test  /= max_val\n",
        "\n",
        "    # 4. Classical SVM\n",
        "    clf = SVC(kernel=\"precomputed\", C=C)\n",
        "    clf.fit(K_train, y_train)\n",
        "\n",
        "    return accuracy_score(y_test, clf.predict(K_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_star = theta_trained  # frozen from Step 2\n",
        "\n",
        "for layers in layers_list:\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Evaluating {layers} layers\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    theta_L = theta_star[:layers]\n",
        "\n",
        "    acc_qek = evaluate_kernel_inference(\n",
        "        qnode_state,\n",
        "        theta_L,\n",
        "        X_train_qek,\n",
        "        X_test_qek,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        C=C,\n",
        "    )\n",
        "\n",
        "    print(f\"QEK accuracy: {acc_qek:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9DiP2gTQN4o",
        "outputId": "2deff1ec-b318-4ac9-8979-8d5a64e51599"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Evaluating 2 layers\n",
            "========================================\n",
            "QEK accuracy: 0.9500\n",
            "\n",
            "========================================\n",
            "Evaluating 4 layers\n",
            "========================================\n",
            "QEK accuracy: 0.9500\n",
            "\n",
            "========================================\n",
            "Evaluating 6 layers\n",
            "========================================\n",
            "QEK accuracy: 0.9500\n",
            "\n",
            "========================================\n",
            "Evaluating 8 layers\n",
            "========================================\n",
            "QEK accuracy: 0.9500\n",
            "\n",
            "========================================\n",
            "Evaluating 10 layers\n",
            "========================================\n",
            "QEK accuracy: 0.9500\n",
            "\n",
            "========================================\n",
            "Evaluating 12 layers\n",
            "========================================\n",
            "QEK accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.linalg.norm(theta_trained[0] - theta_trained[1]))\n",
        "print(np.linalg.norm(theta_trained[1] - theta_trained[2]))\n",
        "print(np.linalg.norm(theta_trained[5] - theta_trained[6]))\n"
      ],
      "metadata": {
        "id": "T_8WbskbV0pY",
        "outputId": "c082199b-be57-4c5c-a179-6a84f610906e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.618622001962192\n",
            "1.7211565376730797\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 5 is out of bounds for axis 0 with size 4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2242378362.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/numpy/tensor.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "U0F6HK86DJYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81830ef-4b4d-4139-fd33-27132ac435b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.95\n"
          ]
        }
      ],
      "source": [
        "print(acc_qek)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KROFpzJsoxfN",
        "LPeJfiDJo-qn",
        "ZxklKVp_qRRT",
        "5yFXHD8Mq--g"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}