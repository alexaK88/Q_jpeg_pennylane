{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexaK88/Q_jpeg_pennylane/blob/main/QEK_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mLT0ZXmusDbv",
        "outputId": "eaa5c851-97f0-43f2-f093-f50a0134fee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray==0.8.2 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (7.0.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.44 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.44.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (26.0)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning>=0.44->pennylane) (0.3.31.22.1)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.46.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: pennylane-lightning[gpu] in /usr/local/lib/python3.12/dist-packages (0.44.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray==0.8.2 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (7.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (26.0)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning[gpu]) (0.3.31.22.1)\n",
            "Requirement already satisfied: pennylane-lightning-gpu in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning[gpu]) (0.44.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Requirement already satisfied: custatevec-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (1.12.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.9.86)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.5.10.65)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.9.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning-gpu->pennylane-lightning[gpu]) (12.9.79)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.46.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane\n",
        "!pip install pennylane pennylane-lightning[gpu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9v8k-78sq8c"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fame-C0QsoGt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pennylane as qml\n",
        "from pennylane.templates import QFT\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import fetch_openml, load_digits\n",
        "from sklearn.preprocessing import MinMaxScaler, normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from pennylane import numpy as pnp\n",
        "from skimage.transform import resize\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPeJfiDJo-qn"
      },
      "source": [
        "### Dataset Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JJh_V_1hfrh"
      },
      "source": [
        "First, we load the MNIST dataset from openML.\n",
        "- X is the pixel data\n",
        "- y is the labels\n",
        "- converting everything to `uint8` here to ensure all values are integers in [0, 255]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "amm-B8_Xdzyf"
      },
      "outputs": [],
      "source": [
        "# loading mnist from openML\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist['data'].astype(np.uint8) # better to convert for binerization\n",
        "y = mnist['target'].astype(np.uint8)\n",
        "y = y.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeMOrBB2ognh"
      },
      "source": [
        "Next, we focus on 2 classes, i.e. binary classification.\n",
        "Here, I've been experimenting with different classes, and I stopped on 4 vs 9, cause they have more subtle difference in pixels, they are similar looking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wNShS1qTpNI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5259df9-5b50-40dd-9dcf-a656649644c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14780, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# focus on binary classification\n",
        "mask = (y == 0) | (y == 1)\n",
        "X, y = X[mask], y[mask]\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qdDAqkBizaZ"
      },
      "source": [
        "- I take only the first `n_samples`.\n",
        "- I convert X to a NumPy array, and shuffling the data randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "GdbQMsOdpoWz"
      },
      "outputs": [],
      "source": [
        "n_samples = 300 # restricting to 6000 samples for now\n",
        "\n",
        "X = X.values if hasattr(X, \"values\") else X # safer conversion\n",
        "\n",
        "X = X[:n_samples]\n",
        "y = y[:n_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFV8_UnGptzJ"
      },
      "source": [
        "Now, I normalise pixel intensities.\n",
        "- [0, 255] -> [0, 1]\n",
        "- reshaping images back to 2D for resizing, i.e to 28x28 array with float values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A69wNTvdppCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81c9de7-b701-46a7-c861-3fbf03550877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 28, 28)\n",
            "Pixel range: 0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "X = X / 255.0\n",
        "X = X.reshape(-1, 28, 28)\n",
        "\n",
        "y = 2 * y - 1 # KTA requires labels in {-1, 1}\n",
        "\n",
        "print(X.shape)\n",
        "print(\"Pixel range:\", X.min(), X.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6fKM38QpyO8"
      },
      "source": [
        "And now I reduce images to 8x8 + flattening to (, 64)\n",
        "- resize -> flatten -> normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zXfPx1nwpq31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0418810-d7b7-4c79-d5a8-cc5cca9e7dbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# convert each 28x28 binarised image to 8x8, then flatten to length 64\n",
        "def to_8x8_vector(img_row):\n",
        "    img_8x8 = resize(\n",
        "        img_row,\n",
        "        (8, 8),\n",
        "        anti_aliasing=False,\n",
        "        preserve_range=True,\n",
        "        order=1 # controlling interpolation\n",
        "    )\n",
        "    img_8x8 = img_8x8.flatten().astype(float)\n",
        "    img_8x8 -= img_8x8.mean()\n",
        "    norm = np.linalg.norm(img_8x8)\n",
        "    if norm > 0:\n",
        "        img_8x8 /= norm\n",
        "    else:\n",
        "        img_8x8[0] = 1.0\n",
        "      # should be shape (64,)\n",
        "    return img_8x8\n",
        "\n",
        "# apply transformation to all images\n",
        "X_8x8 = np.array([to_8x8_vector(x) for x in X], dtype=float)\n",
        "X_8x8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ycrMsoOtp2BY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e673fe21-7801-43c2-f8e3-20314b69bde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any NaNs? False\n",
            "Norm check: 0.9999999999999998 1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "# sanity check, make sure no NaNs exist and all vectors are normalised, i.e. norm is around 1\n",
        "print(\"Any NaNs?\", np.isnan(X_8x8).any())\n",
        "print(\"Norm check:\", np.min(np.linalg.norm(X_8x8, axis=1)), np.max(np.linalg.norm(X_8x8, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUuSiBQfp_Sf"
      },
      "source": [
        "I'm gonna do the splitting here, and carry both representations consistently.\n",
        "- qek inputs: (64,) flattened and normalized vectors, for quantum kernel embedding\n",
        "- qjpeg: 28x28 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CbFUj8-Zp9fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ace0d0-a830-423c-a5c9-358e157e8c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QEK train/test: (240, 64) (60, 64)\n",
            "IMG train/test: (240, 28, 28) (60, 28, 28)\n",
            "Labels train/test: (240,) (60,)\n"
          ]
        }
      ],
      "source": [
        "idx = np.arange(n_samples)\n",
        "\n",
        "idx_train, idx_test, y_train, y_test = train_test_split(\n",
        "    idx, y, test_size=0.2, random_state=42, stratify=y, shuffle=True\n",
        ")\n",
        "\n",
        "# QEK inputs (8x8 -> 64 -> normed)\n",
        "X_train_qek = X_8x8[idx_train]\n",
        "X_test_qek  = X_8x8[idx_test]\n",
        "\n",
        "# QJPEG inputs (28x28 binary images)\n",
        "X_train_img = X[idx_train]\n",
        "X_test_img  = X[idx_test]\n",
        "\n",
        "print(\"QEK train/test:\", X_train_qek.shape, X_test_qek.shape)\n",
        "print(\"IMG train/test:\", X_train_img.shape, X_test_img.shape)\n",
        "print(\"Labels train/test:\", y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQUmF-0YqOjS"
      },
      "source": [
        "Data preparation is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxklKVp_qRRT"
      },
      "source": [
        "### Quantum Embedding & Kernel Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiuzYJktY-lT"
      },
      "source": [
        "Define number of qubits and device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g1l-xD10kYsG"
      },
      "outputs": [],
      "source": [
        "device = \"lightning.qubit\"\n",
        "n_qubits = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NDnTjviKqYmk"
      },
      "outputs": [],
      "source": [
        "dev = qml.device(device, wires=n_qubits, shots=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54-8ETQgqrnD"
      },
      "source": [
        "Defining the parametrised quantum circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wfl2qs-lwH_k"
      },
      "outputs": [],
      "source": [
        "def quantum_circuit(x, theta):\n",
        "\n",
        "    # Trainable block FIRST\n",
        "    for l in range(theta.shape[0]):\n",
        "\n",
        "        for q in range(n_qubits):\n",
        "            qml.RY(theta[l, q, 0], wires=q)\n",
        "            qml.RZ(theta[l, q, 1], wires=q)\n",
        "\n",
        "        for q in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[q, q + 1])\n",
        "\n",
        "        for q in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[q + 1, q])\n",
        "\n",
        "    # THEN embed data\n",
        "    qml.AmplitudeEmbedding(\n",
        "        x,\n",
        "        wires=range(n_qubits),\n",
        "        normalize=False\n",
        "    )\n",
        "\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qek_kernel(x1, x2, theta):\n",
        "    quantum_circuit(x1, theta)\n",
        "    qml.adjoint(quantum_circuit)(x2, theta)\n",
        "    return qml.expval(qml.Projector([0]*n_qubits, wires=range(n_qubits)))\n",
        "\n",
        "def compute_kernel_matrix(X1, X2, theta):\n",
        "    \"\"\"\n",
        "    Compute the quantum kernel matrix K_ij = K_theta(X1[i], X2[j])\n",
        "\n",
        "    Args:\n",
        "        X1: array of shape (N1, d)\n",
        "        X2: array of shape (N2, d)\n",
        "        theta: trained QEK parameters\n",
        "\n",
        "    Returns:\n",
        "        K: (N1, N2) kernel matrix\n",
        "    \"\"\"\n",
        "    N1, N2 = len(X1), len(X2)\n",
        "    K = np.zeros((N1, N2))\n",
        "\n",
        "    for i in range(N1):\n",
        "        for j in range(N2):\n",
        "            K[i, j] = qek_kernel(X1[i], X2[j], theta)\n",
        "\n",
        "    return K\n",
        "\n",
        "def kta_loss_full(theta, X, y):\n",
        "    def _kernel(x1, x2):\n",
        "        return qek_kernel(x1, x2, theta)\n",
        "    return -qml.kernels.target_alignment(X_train_qek, y_train, kernel=_kernel)\n",
        "\n",
        "\n",
        "def kta_loss_minibatch(theta, X, y, batch_size=8):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    Xb = X[idx]\n",
        "    yb = y[idx]\n",
        "\n",
        "    # Define a kernel function that takes x1, x2 and uses the current theta\n",
        "    def _kernel_fn(x1, x2):\n",
        "        return qek_kernel(x1, x2, theta)\n",
        "\n",
        "    # PennyLane's KTA\n",
        "    return -qml.kernels.target_alignment(Xb, yb, kernel=_kernel_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NogXc_2oV-L0"
      },
      "outputs": [],
      "source": [
        "n_layers = 1\n",
        "n_steps = 500\n",
        "batch_size = 64\n",
        "stepsize = 1e-3\n",
        "momentum = 0.9\n",
        "\n",
        "subset_train = 50\n",
        "subset_test  = 50\n",
        "\n",
        "X_train_subset = X_train_qek[:subset_train]\n",
        "y_train_subset = y_train[:subset_train]\n",
        "\n",
        "theta = 0.3 * pnp.random.randn(n_layers, n_qubits, 2)\n",
        "opt = qml.NesterovMomentumOptimizer(stepsize=stepsize, momentum=momentum)\n",
        "\n",
        "ema = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = compute_kernel_matrix(X_train_subset, X_train_subset, theta)\n",
        "\n",
        "# this is a pure sanity check of the kernel on a subset of samples\n",
        "print(\"Kernel min :\", K.min())\n",
        "print(\"Kernel max :\", K.max())\n",
        "print(\"Kernel mean:\", K.mean())\n",
        "\n",
        "# Symmetry check (should be ~0)\n",
        "print(\"Symmetry error:\", np.max(np.abs(K - K.T)))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EBKYDvEsRlUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf6660d-c48b-4977-fbef-308edb52d03c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel min : 1.571060396386143e-05\n",
            "Kernel max : 1.0000000000000093\n",
            "Kernel mean: 0.18054491425671446\n",
            "Symmetry error: 1.9984014443252818e-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad = qml.grad(lambda t: kta_loss_full(t, X_train_qek, y_train))(theta)\n",
        "print(\"Grad norm:\", np.linalg.norm(grad))\n"
      ],
      "metadata": {
        "id": "yU16LHsSRVAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta_pert = theta + 0.1 * np.random.randn(*theta.shape)\n",
        "print(\"Loss perturbed:\", kta_loss_full(theta_pert, X_train_qek, y_train))\n"
      ],
      "metadata": {
        "id": "6menwM-lStSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIHEp4b3wb-p",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for step in range(n_steps):\n",
        "    theta, loss = opt.step_and_cost(\n",
        "        lambda t: kta_loss_minibatch(\n",
        "            t, X_train_qek, y_train, batch_size\n",
        "        ),\n",
        "        theta\n",
        "    )\n",
        "    loss = qml.math.clip(loss, -1.0, 1.0) # clipping stabilizes gradients\n",
        "\n",
        "    ema = loss if ema is None else 0.9 * ema + 0.1 * loss\n",
        "    current_time = time.time()\n",
        "    if step % 20 == 0:\n",
        "        # loss_full = kta_loss_full(theta, X_train_qek, y_train)\n",
        "        print(f\"Step {step:02d} | loss={loss:.4f} | ema={ema:.4f} | time elapsed={int(current_time - start_time)}\")\n",
        "    start_time = current_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "K = compute_kernel_matrix(X_train_subset, X_train_subset, theta)\n",
        "\n",
        "# visualise the kernel\n",
        "plt.imshow(K, cmap=\"viridis\")\n",
        "plt.colorbar()\n",
        "plt.title(\"Trained QEK kernel\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DOW7SWVVVxu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olzE5vbKXe4V"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_test_subset = X_test_qek[:subset_test]\n",
        "y_test_subset = y_test[:subset_test]\n",
        "\n",
        "# Compute kernel matrices using your trained theta\n",
        "def compute_kernel_matrix(X1, X2, theta):\n",
        "    N1, N2 = len(X1), len(X2)\n",
        "    K = np.zeros((N1, N2))\n",
        "    for i in range(N1):\n",
        "        for j in range(N2):\n",
        "            K[i, j] = qek_kernel(X1[i], X2[j], theta)\n",
        "    return K\n",
        "\n",
        "# Training kernel\n",
        "K_train = compute_kernel_matrix(X_train_subset, X_train_subset, theta)\n",
        "# Testing kernel\n",
        "K_test  = compute_kernel_matrix(X_test_subset, X_train_subset, theta)\n",
        "\n",
        "# SVM with precomputed kernel\n",
        "svm = SVC(kernel='precomputed')\n",
        "svm.fit(K_train, y_train_subset)\n",
        "\n",
        "# Predict & evaluate\n",
        "y_pred = svm.predict(K_test)\n",
        "acc = accuracy_score(y_test_subset, y_pred)\n",
        "\n",
        "print(f\"SVM accuracy with trained QEK kernel: {acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODqPFcd9DhIxLvSQ7bbscY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}